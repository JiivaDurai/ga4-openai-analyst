Directory: ga4-bigquery-analyst

Directory Structure:
```
.
├── .gitignore

```

Contents of app.yaml:
```
runtime: python312

entrypoint: streamlit run app.py --server.enableCORS false --browser.serverAddress 0.0.0.0 --browser.gatherUsageStats false --server.port $PORT
```

Contents of manual_works.py:
```
from openai import OpenAI
import os
# from dotenv import load_dotenv
from function_schema import tools
# Load environment variables from .env file
# load_dotenv()

# Access the variables

client = OpenAI()


assistant = client.beta.assistants.create(
    name="Assistant",
    instructions="You are Bigquery SQL generator assistant.. And help me build queries for our DW to analyse multiple queries.",
    tools=tools,
    model="gpt-4o",
)

print(assistant.id)
```

Contents of requirements.txt:
```
google-cloud-bigquery==3.25.0
openai==1.40.3
streamlit==1.37.1
```

Contents of function_schema.py:
```
# Define the JSON schema for the functions
tools = [{
    "type": "function",
    "function": 
        {
        "name": "execute_sql_query",
        "description": "Execute an SQL query on BigQuery and return the results.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The SQL query to execute."
                }
            },
            "required": ["query"],
            "additionalProperties": False,
        }
    }},
         {
    "type": "function",
    "function": 
    {
        "name": "get_table_schema",
        "description": "Fetch the schema of a specified table from BigQuery.",
        "parameters": {
            "type": "object",
            "properties": {
                "dataset": {
                    "type": "string",
                    "description": "The name of the dataset containing the table."
                },
                "table_name": {
                    "type": "string",
                    "description": "The name of the table to fetch the schema for."
                }
            },
            "required": ["dataset", "table_name"],
            "additionalProperties": False,
        }
    }
         }
]
```

Contents of README.md:
```
# ga4-openai-analyst
# ga4-openai-analyst

```

Contents of bigquery_functions.py:
```
from google.cloud import bigquery

client = bigquery.Client(project="cl-test-project")

# Define the functions that can be called
def execute_sql_query(query: str) -> dict:
    try:
        query_job = client.query(query)
        result = query_job.result()
        rows = [dict(row) for row in result]
        return {"status": "success", "data": rows}
    except Exception as e:
        return {"status": "error", "error": str(e)}

def get_table_schema(dataset: str, table_name: str) -> dict:
    try:
        table_ref = client.dataset(dataset).table(table_name)
        table = client.get_table(table_ref)
        schema = [{"name": field.name, "type": field.field_type} for field in table.schema]
        return schema
    except Exception as e:
        return {"status": "error", "error": str(e)}
```

Contents of Procfile:
```
web: streamlit run main.py --server.port $PORT

```

Contents of main.py:
```

from function_schema import tools
from bigquery_functions import execute_sql_query, get_table_schema
import streamlit as st
from open_ai import client, assistant_id
from open_ai import EventHandler



# Streamlit app layout
st.title("Bigquery SQL Assistant with Function Calling")

# Input box for user queries
text_box = st.empty()


# Initialize chat history in session state if not already done
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if "assistant_text" not in st.session_state:
    st.session_state.assistant_text = [""]

if "thread_id" not in st.session_state:
    thread = client.beta.threads.create()
    st.session_state.thread_id = thread.id

if "text_boxes" not in st.session_state:
    st.session_state.text_boxes = []

def display_chat_history():
    for role, content in st.session_state.chat_history:
        if role == "user":
            st.chat_message("User").write(content)
        else:
            st.chat_message("Assistant").write(content)

display_chat_history()

if prompt := st.chat_input("Enter your message"):
    # query_extra = f"This is the users details for the query request if the user asks any question on SQL \
    #     \n User details: \n User ID: Kasamuki \n User Name: Potato Chips \n \
    #         User dataset: cl3967trkvbts3, Tablename: events_202309" 
    st.session_state.chat_history.append(("user", prompt))

    # Assuming the user input is related to calculating tax
    # if "tax" in prompt.lower():  # You can adjust this condition based on your actual use case
    #     try:
    #         tax_result = calculate_tax(prompt)  # Assuming prompt contains revenue
    #         st.session_state.chat_history.append(
    #             ("assistant", f"Tax for revenue {tax_result['revenue']}: {tax_result['tax']}"))
    #     except ValueError as e:
    #         st.session_state.chat_history.append(("assistant", str(e)))
    

    client.beta.threads.messages.create(
        thread_id=st.session_state.thread_id,
        role="user",
        content=prompt,        
    )

    st.session_state.text_boxes.append(st.empty())
    st.session_state.text_boxes[-1].success(f" {prompt}")

    with client.beta.threads.runs.stream(thread_id=st.session_state.thread_id,
                                         assistant_id=assistant_id,
                                         event_handler=EventHandler(),
                                         temperature=0) as stream:
        stream.until_done()

```

Contents of __ini__.py:
```

```

Contents of open_ai.py:
```
from openai import OpenAI
import os
# from dotenv import load_dotenv
import ast
import streamlit as st
from openai import  AssistantEventHandler
from typing_extensions import override
# from dotenv import load_dotenv
from openai.types.beta.threads import Text, TextDelta
from bigquery_functions import execute_sql_query, get_table_schema

# Load environment variables from .env file
# load_dotenv()

# Load the OpenAI API key from the environment variable
# set from the .env file
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


client = OpenAI()


# assistant = client.beta.assistants.create(
#     name="Assistant",
#     instructions="",
#     tools=tools,
#     model="gpt-4o",
# )

## Fixed assistant_id
assistant_id = "asst_9S6Eij8icii5vHcwqntwRXVL"


class EventHandler(AssistantEventHandler):
    """
    Event handler for the assistant stream
    """

    @override
    def on_event(self, event):
        # Retrieve events that are denoted with 'requires_action'
        # since these will have our tool_calls
        if event.event == 'thread.run.requires_action':
            run_id = event.data.id  # Retrieve the run ID from the event data
            self.handle_requires_action(event.data, run_id)

    @override
    def on_text_created(self, text: Text) -> None:
        """
        Handler for when a text is created
        """
        # This try-except block will update the earlier expander for code to complete.
        # Note the indexing. We are updating the x-1 textbox where x is the current textbox.
        # Note how `on_tool_call_done` creates a new textbook (which is the x_th textbox, so we want to access the x-1_th)
        # This is to address an edge case where code is executed, but there is no output textbox (e.g. a graph is created)
        try:
            st.session_state[f"code_expander_{len(st.session_state.text_boxes) - 1}"].update(state="complete",
                                                                                             expanded=False)
        except KeyError:
            pass

        # Create a new text box
        st.session_state.text_boxes.append(st.empty())
        # Display the text in the newly created text box
        st.session_state.text_boxes[-1].info("".join(st.session_state["assistant_text"][-1]))

    @override
    def on_text_delta(self, delta: TextDelta, snapshot: Text):
        """
        Handler for when a text delta is created
        """
        # Clear the latest text box
        st.session_state.text_boxes[-1].empty()
        # If there is text written, add it to latest element in the assistant text list
        if delta.value:
            st.session_state.assistant_text[-1] += delta.value
            #st.session_state.chat_history.append(("assistant", delta.value))
        # Re-display the full text in the latest text box
        st.session_state.text_boxes[-1].info("".join(st.session_state["assistant_text"][-1]))

    def on_text_done(self, text: Text):
        """
        Handler for when text is done
        """
        # Create new text box and element in the assistant text list
        st.session_state.text_boxes.append(st.empty())
        st.session_state.assistant_text.append("")
        st.session_state.chat_history.append(("assistant", text.value))
    def handle_requires_action(self, data, run_id):
        tool_outputs = []

        for tool in data.required_action.submit_tool_outputs.tool_calls:
            if tool.function.name == "execute_sql_query":
                try:
                    # Extract revenue from tool parameters
                    query = ast.literal_eval(tool.function.arguments)["query"]
                    # Call your calculate_tax function to get the tax
                    query_result = execute_sql_query(query)
                    # Append tool output in the required format
                    tool_outputs.append({"tool_call_id": tool.id, "output": f"{query_result}"})
                except ValueError as e:
                    # Handle any errors when calculating tax
                    tool_outputs.append({"tool_call_id": tool.id, "error": str(e)})
            elif tool.function.name == "get_table_schema":
                try:
                    # Extract revenue from tool parameters
                    dataset = ast.literal_eval(tool.function.arguments)["dataset"]
                    table_name = ast.literal_eval(tool.function.arguments)["table_name"]
                    # Call your calculate_tax function to get the tax
                    table_schema_result = get_table_schema(dataset, table_name)
                    # Append tool output in the required format
                    tool_outputs.append({"tool_call_id": tool.id, "output": f"{table_schema_result}"})
                except ValueError as e:
                    # Handle any errors when calculating tax
                    tool_outputs.append({"tool_call_id": tool.id, "error": str(e)})
        # Submit all tool_outputs at the same time
        self.submit_tool_outputs(tool_outputs)

    def submit_tool_outputs(self, tool_outputs):
        # Use the submit_tool_outputs_stream helper
        with client.beta.threads.runs.submit_tool_outputs_stream(
                thread_id=self.current_run.thread_id,
                run_id=self.current_run.id,
                tool_outputs=tool_outputs,
                event_handler=EventHandler(),
        ) as stream:
            for text in stream.text_deltas:
                print(text, end="", flush=True)
            # print()
```

